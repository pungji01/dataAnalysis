{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46265587",
   "metadata": {
    "id": "46265587"
   },
   "source": [
    "# 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "go-R3kQSaSrk",
   "metadata": {
    "id": "go-R3kQSaSrk"
   },
   "source": [
    "## 5. OpenAPI를 이용한 데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b715273",
   "metadata": {},
   "source": [
    "- <a href=\"#1)OpenAPI통한데이터수집\">1) OpenAPI 통한 데이터 수집</a>\n",
    "- <a href=\"#2)한글텍스트Cleansing\">2) 한글 텍스트 Cleansing</a>\n",
    "- <a href=\"#3)웹이미지수집하기\">3) 웹 이미지 수집하기</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VGDzYiKZhR0U",
   "metadata": {
    "id": "VGDzYiKZhR0U"
   },
   "source": [
    "### #그래프에서 한글사용하는 방법\n",
    "- **(코랩에서)한글폰트 설치하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hwAJP1nahhrF",
   "metadata": {
    "id": "hwAJP1nahhrF"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install -y fonts-nanum\n",
    "!sudo fc-cache -fv\n",
    "!rm ~/.cache/matplotlib -rf\n",
    "\n",
    "# 코랩에서 위 코드를 실행시킨 후  반드시 코랩 메뉴: \"런타임>런타임 다시 시작\" 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4YrZX8Hf1hQ8",
   "metadata": {
    "id": "4YrZX8Hf1hQ8"
   },
   "source": [
    "- **한글 폰트 지정하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CfuS0iwGhhee",
   "metadata": {
    "id": "CfuS0iwGhhee"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ld3tL_Sh1gXu",
   "metadata": {
    "id": "ld3tL_Sh1gXu"
   },
   "outputs": [],
   "source": [
    "# 코랩에서 한글 폰트 종류와 이름이 win과 다를 수 있다!!!\n",
    "# 코랩: NanumGothic, 윈도우: Malgun Gothic\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.family': 'Malgun Gothic',\n",
    "                     'font.size': 12,\n",
    "                     'figure.figsize': (6, 4),\n",
    "                     'axes.unicode_minus':  False }) # 폰트 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c04ae",
   "metadata": {
    "id": "6d0c04ae"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f12800",
   "metadata": {
    "id": "f4f12800"
   },
   "source": [
    "### <a name=\"1)OpenAPI통한데이터수집\">1) OpenAPI 통한 데이터 수집</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db60e9f8",
   "metadata": {
    "id": "db60e9f8"
   },
   "source": [
    "#### 1.네이버 OpenAPI 신청하기\n",
    "* 네이버 검색(책, 뉴스, 쇼핑)\n",
    "    - 네이버 OpenAPI 소개: https://developers.naver.com/products/intro/plan/\n",
    "    - 개발 가이드 보기: https://developers.naver.com/docs/serviceapi/search/news\n",
    "    - OpenAPI 신청하기: https://developers.naver.com/apps/#/register"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6093ed93",
   "metadata": {
    "id": "6093ed93"
   },
   "source": [
    "#### 2.네이버 OpenAPI 사용하기\n",
    "* 검색\n",
    "    - 1.책 검색\n",
    "    - 2.뉴스 검색\n",
    "    - 3.쇼핑 검색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0245934c",
   "metadata": {
    "id": "0245934c"
   },
   "source": [
    "#### [실습] : 네이버 검색 API 사용하여 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bbff90",
   "metadata": {
    "id": "51bbff90"
   },
   "outputs": [],
   "source": [
    "# 정적 크롤링을 위한 requests 설치\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03fe1289",
   "metadata": {
    "id": "03fe1289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "    네이버 검색 대상입니다.\n",
      "      1.book,  2.news,  3.shop\n",
      "    -----------------------------\n",
      "[2024년04월25일 12시12분56초] Url Request Success\n",
      "HTTP Error 400: Bad Request\n",
      "[2024년04월25일 12시12분56초] Error for URL : https://openapi.naver.com/v1/search/shop.json?query=%EB%B4%84%EC%9B%90%ED%94%BC%EC%8A%A4&start=101&display=1601390\n",
      "가져온 데이터 : 100 건\n",
      "./data/naver_shop_봄원피스.csv SAVED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>브랜드</th>\n",
       "      <th>제조사</th>\n",
       "      <th>가격</th>\n",
       "      <th>이미지</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(S,M,L,XL) &lt;b&gt;봄&lt;/b&gt; 여성 정장&lt;b&gt;원피스&lt;/b&gt; 빅사이즈&lt;b&gt;원피스...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>69000</td>\n",
       "      <td>https://shopping-phinf.pstatic.net/main_847762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;b&gt;봄&lt;/b&gt; 여름 롱 &lt;b&gt;원피스&lt;/b&gt; 바스락 휴양지 반팔 후드 맨투맨 하객 ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10000</td>\n",
       "      <td>https://shopping-phinf.pstatic.net/main_847995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;b&gt;봄&lt;/b&gt; 하객&lt;b&gt;원피스&lt;/b&gt; 결혼식 77 빅사이즈 셔츠&lt;b&gt;원피스&lt;/b&gt;...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>68400</td>\n",
       "      <td>https://shopping-phinf.pstatic.net/main_850579...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>여름 &lt;b&gt;원피스&lt;/b&gt; 빅사이즈 88 99 스트라이프 반팔 니트 롱 &lt;b&gt;원피스&lt;...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>23800</td>\n",
       "      <td>https://shopping-phinf.pstatic.net/main_861527...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>자라 데님&lt;b&gt;원피스&lt;/b&gt;</td>\n",
       "      <td>자라</td>\n",
       "      <td></td>\n",
       "      <td>35700</td>\n",
       "      <td>https://shopping-phinf.pstatic.net/main_872853...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[L-4XL/빅사이즈] 진짜 여신 레이어드 롱원피스 &lt;b&gt;봄원피스&lt;/b&gt; 나시원피스...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>29900</td>\n",
       "      <td>https://shopping-phinf.pstatic.net/main_876017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>라코스테 사선 &lt;b&gt;원피스&lt;/b&gt; 플라켓 폴로드레스 깔끔한 데일리 &lt;b&gt;봄&lt;/b&gt; ...</td>\n",
       "      <td>라코스테</td>\n",
       "      <td>동일드방레</td>\n",
       "      <td>149500</td>\n",
       "      <td>https://shopping-phinf.pstatic.net/main_875966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>카라 단가라 반팔 니트 티셔츠 레이어드 배색 주름 플리츠 롱&lt;b&gt;원피스&lt;/b&gt; &lt;b...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>36800</td>\n",
       "      <td>https://shopping-phinf.pstatic.net/main_461195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>드노 데님 스퀘어 뷔스티에 허리끈 롱&lt;b&gt;원피스&lt;/b&gt; 1col &lt;b&gt;봄&lt;/b&gt; 가...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>29500</td>\n",
       "      <td>https://shopping-phinf.pstatic.net/main_857609...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>기간한정 슈크림 엠보 자수 A라인 캉캉 티어드 민소매 뷔스티에 &lt;b&gt;봄&lt;/b&gt; 미니...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>22800</td>\n",
       "      <td>https://shopping-phinf.pstatic.net/main_461405...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   제목   브랜드    제조사      가격  \\\n",
       "0   (S,M,L,XL) <b>봄</b> 여성 정장<b>원피스</b> 빅사이즈<b>원피스...                69000   \n",
       "1   <b>봄</b> 여름 롱 <b>원피스</b> 바스락 휴양지 반팔 후드 맨투맨 하객 ...                10000   \n",
       "2   <b>봄</b> 하객<b>원피스</b> 결혼식 77 빅사이즈 셔츠<b>원피스</b>...                68400   \n",
       "3   여름 <b>원피스</b> 빅사이즈 88 99 스트라이프 반팔 니트 롱 <b>원피스<...                23800   \n",
       "4                                     자라 데님<b>원피스</b>    자라          35700   \n",
       "..                                                ...   ...    ...     ...   \n",
       "95  [L-4XL/빅사이즈] 진짜 여신 레이어드 롱원피스 <b>봄원피스</b> 나시원피스...                29900   \n",
       "96  라코스테 사선 <b>원피스</b> 플라켓 폴로드레스 깔끔한 데일리 <b>봄</b> ...  라코스테  동일드방레  149500   \n",
       "97  카라 단가라 반팔 니트 티셔츠 레이어드 배색 주름 플리츠 롱<b>원피스</b> <b...                36800   \n",
       "98  드노 데님 스퀘어 뷔스티에 허리끈 롱<b>원피스</b> 1col <b>봄</b> 가...                29500   \n",
       "99  기간한정 슈크림 엠보 자수 A라인 캉캉 티어드 민소매 뷔스티에 <b>봄</b> 미니...                22800   \n",
       "\n",
       "                                                  이미지  \n",
       "0   https://shopping-phinf.pstatic.net/main_847762...  \n",
       "1   https://shopping-phinf.pstatic.net/main_847995...  \n",
       "2   https://shopping-phinf.pstatic.net/main_850579...  \n",
       "3   https://shopping-phinf.pstatic.net/main_861527...  \n",
       "4   https://shopping-phinf.pstatic.net/main_872853...  \n",
       "..                                                ...  \n",
       "95  https://shopping-phinf.pstatic.net/main_876017...  \n",
       "96  https://shopping-phinf.pstatic.net/main_875966...  \n",
       "97  https://shopping-phinf.pstatic.net/main_461195...  \n",
       "98  https://shopping-phinf.pstatic.net/main_857609...  \n",
       "99  https://shopping-phinf.pstatic.net/main_461405...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "datas = []   #csv파일을 위한 변수\n",
    "\n",
    "client_id = 'b5kDna4hBQsYKiJ1TwNl'          # 자신의 client_id\n",
    "client_pw = 'xNFuRQ69Hd'          # 자신의 client_secret\n",
    "PATH = './data'         # 수집 데이터 저장 폴더\n",
    "\n",
    "\n",
    "#[CODE 1]\n",
    "def get_RequestUrl(url):\n",
    "    req = urllib.request.Request(url)\n",
    "    req.add_header(\"X-Naver-Client-Id\", client_id)\n",
    "    req.add_header(\"X-Naver-Client-Secret\", client_pw)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "        if response.getcode() == 200:\n",
    "            print(f\"[{now.strftime('%Y년%m월%d일 %H시%M분%S초')}] Url Request Success\")\n",
    "            return response.read().decode('utf-8')\n",
    "\n",
    "    except Exception as e:\n",
    "#         if response.getcode() == 400 and datas:\n",
    "#             return None\n",
    "        print(e)\n",
    "        print(f\"[{now.strftime('%Y년%m월%d일 %H시%M분%S초')}] Error for URL : {url}\" )\n",
    "        return None\n",
    "\n",
    "\n",
    "#[CODE 2]  네이버 검색 API\n",
    "def get_NaverSearch(node, keyword, start, display):\n",
    "    base = \"https://openapi.naver.com/v1/search\"\n",
    "    node = \"/%s.json\" % node\n",
    "    parameters = \"?query=%s&start=%s&display=%s\" % (urllib.parse.quote(keyword), start, display)\n",
    "\n",
    "    url = base + node + parameters\n",
    "    responseDecode = get_RequestUrl(url)   #[CODE 1]\n",
    "\n",
    "    if (responseDecode == None):\n",
    "        return None\n",
    "    else:\n",
    "        return json.loads(responseDecode)\n",
    "\n",
    "#[CODE 3]\n",
    "def get_PostData(node, post, jsonResult, cnt):\n",
    "    if node == 'book':\n",
    "        data = {'제목':post['title'],\n",
    "                '저자':post['author'],\n",
    "                '출판사':post['publisher'],\n",
    "                '출간일':post['pubdate'],\n",
    "                '링크':post['link'],\n",
    "                '이미지':post['image']}\n",
    "    elif node == 'news':\n",
    "        data = {'제목':post['title'],\n",
    "                '링크':post['originallink'],\n",
    "                '내용':post['description']}\n",
    "    elif node == 'shop':\n",
    "        data = {'제목':post['title'],\n",
    "                '브랜드':post['brand'],\n",
    "                '제조사':post['maker'],\n",
    "                '가격':post['lprice'],\n",
    "                '이미지':post['image']}\n",
    "\n",
    "    jsonResult.append(data)\n",
    "    datas.append(data)\n",
    "\n",
    "    return\n",
    "\n",
    "#[CODE 0]\n",
    "def main():\n",
    "    global node, keyword\n",
    "\n",
    "    nodeType = '''-----------------------------\n",
    "    네이버 검색 대상입니다.\n",
    "      1.book,  2.news,  3.shop\n",
    "    -----------------------------'''\n",
    "    print(nodeType)\n",
    "    node = input('번호를 선택하세요.[1:책, 2:뉴스, 3:쇼핑]')\n",
    "    if node == '1': node = 'book'\n",
    "    elif node == '2': node = 'news'\n",
    "    elif node == '3': node = 'shop'\n",
    "    else:\n",
    "        node == '1'\n",
    "        node = 'book'\n",
    "\n",
    "    keyword = input(f'{node} 검색할 검색어를 입력하세요: ')\n",
    "\n",
    "    display, cnt = 100, 0\n",
    "    jsonResult = []\n",
    "    jsonResponse = get_NaverSearch(node, keyword, 1, display)  #[CODE 2]\n",
    "    total = jsonResponse['total']\n",
    "\n",
    "    while ((jsonResponse != None) and (jsonResponse['display'] != 0)):\n",
    "        for post in jsonResponse['items']:\n",
    "            cnt += 1\n",
    "            get_PostData(node, post, jsonResult, cnt)  #[CODE 3]\n",
    "\n",
    "        start = jsonResponse['start'] + jsonResponse['display']\n",
    "        jsonResponse = get_NaverSearch(node, keyword, start, total)\n",
    "#     print(f'가져올 데이터 : {total} 건')\n",
    "\n",
    "    # with open(f'{PATH}/naver_{node}_{keyword}', 'w', encoding='utf8') as outfile:\n",
    "    #     jsonFile = json.dumps(jsonResult,  indent=4, sort_keys=True,  ensure_ascii=False)\n",
    "\n",
    "    #     outfile.write(jsonFile)\n",
    "\n",
    "    print(\"가져온 데이터 : %d 건\" %(cnt))\n",
    "\n",
    "\n",
    "\n",
    "    # csv 파일로 저장하기\n",
    "    file = f'{PATH}/naver_{node}_{keyword}.csv'\n",
    "    df = pd.DataFrame(datas)\n",
    "    df.to_csv(file, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f'{PATH}/naver_{node}_{keyword}.csv SAVED')\n",
    "    return df\n",
    "\n",
    "#-----------\n",
    "# 시작\n",
    "#-----------\n",
    "df = main()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6lHcEMfHjLfk",
   "metadata": {
    "id": "6lHcEMfHjLfk"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27fa6d",
   "metadata": {
    "id": "7a27fa6d"
   },
   "source": [
    "#### (24.2.29 서비스 종료됨)[실습] :  네이버 Papago API 사용하여 번역하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6e522",
   "metadata": {
    "id": "c8b6e522",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import urllib.request\n",
    "# import datetime\n",
    "# import json\n",
    "\n",
    "\n",
    "# client_id = ''  # 자신의 파파고 NMT API ID\n",
    "# client_pw = ''            # 자신의 파파고 NMT API PASSWORD\n",
    "\n",
    "# news = []   #csv파일을 위한 변수\n",
    "\n",
    "# #[CODE 1]\n",
    "# def papago(prompt, lang=1):\n",
    "\n",
    "#     encText = urllib.parse.quote(prompt)\n",
    "#     if lang == 1 :\n",
    "#         data = \"source=ko&target=en&text=\" + encText\n",
    "#     else:\n",
    "#         data = \"source=en&target=ko&text=\" + encText\n",
    "#     url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
    "\n",
    "#     req = urllib.request.Request(url)\n",
    "#     req.add_header(\"X-Naver-Client-Id\", client_id)\n",
    "#     req.add_header(\"X-Naver-Client-Secret\", client_pw)\n",
    "\n",
    "#     try:\n",
    "#         response = urllib.request.urlopen(req, data=data.encode(\"utf-8\") )\n",
    "#         if response.getcode() == 200:\n",
    "#             print(f\"[{now.strftime('%Y년%m월%d일 %H시%M분%S초')}] Url Request Success\")\n",
    "#             responseDecode = response.read().decode('utf-8')\n",
    "\n",
    "#             if responseDecode == None:\n",
    "#                 return None\n",
    "#             else:\n",
    "#                 return json.loads(responseDecode)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(\"[%s] Error for URL : %s\" % (datetime.datetime.now(), url))\n",
    "#         return None\n",
    "\n",
    "# # 메인\n",
    "# lang= int(input('[선택] 1:한글->영어, 2:영어->한글: '))\n",
    "# txt =  '한글' if lang==1 else '영어'\n",
    "# prompt= input(f'[번역] 변환할 문장을 입력하세요.[{txt}로 입력]: ')\n",
    "\n",
    "# jsonResponse = papago(prompt, lang)  # 파파고 번역\n",
    "# jsonResponse\n",
    "# print('-'*50)\n",
    "# print(f\"[번역 결과] => {jsonResponse['message']['result']['translatedText']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56f180",
   "metadata": {
    "id": "aa56f180"
   },
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OARyiX8OjSDk",
   "metadata": {
    "id": "OARyiX8OjSDk"
   },
   "source": [
    "### <a name=\"2)한글텍스트Cleansing\">2) 한글 텍스트 Cleansing</a> :코랩에서 하는게 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iSHlDdMOkhPa",
   "metadata": {
    "id": "iSHlDdMOkhPa"
   },
   "source": [
    "#### 1.라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yW92MW8gjwcV",
   "metadata": {
    "id": "yW92MW8gjwcV"
   },
   "outputs": [],
   "source": [
    "# 자연어처리 형태소 분석 및 토큰화\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xG_Jjc3Vjyvn",
   "metadata": {
    "id": "xG_Jjc3Vjyvn"
   },
   "outputs": [],
   "source": [
    "# (한글)자연어처리 형태소 분석 및 토큰화\n",
    "# (WinOS에서는 konlpy를 사용하기 위해 JDK를 설치해야 오류가 없어 코랩에서 실행함)\n",
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QnXMfe_tj2Tr",
   "metadata": {
    "id": "QnXMfe_tj2Tr"
   },
   "outputs": [],
   "source": [
    "# html tag parsing을 위한 라이브러리\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MYcUubDGfUjr",
   "metadata": {
    "id": "MYcUubDGfUjr"
   },
   "outputs": [],
   "source": [
    "# 사이킷런 CountVectorizer클래스 사용 : 단어 빈도수 추출\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tQ6-YXHGkkCN",
   "metadata": {
    "id": "tQ6-YXHGkkCN"
   },
   "source": [
    "#### 2.한글 테스트 자연어 처리(Text Cleansing)\n",
    "- 앞에서 OpenAPI를 사용하여 뉴스 데이터를 가져온 뒤에 아래 코트를 실행시키도록 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bBQc3PLwjLzQ",
   "metadata": {
    "id": "bBQc3PLwjLzQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import konlpy\n",
    "import nltk\n",
    "\n",
    "def clean_korean_documents(documents):\n",
    "    #텍스트 정제 (HTML 태그 제거)\n",
    "    for i, document in enumerate(documents):\n",
    "        document = BeautifulSoup(document, 'html.parser').text\n",
    "        documents[i] = document\n",
    "\n",
    "    #텍스트 정제 (특수기호 제거)\n",
    "    for i, document in enumerate(documents):\n",
    "        document = re.sub(r'[^ ㄱ-ㅣ가-힣]', '', document) #특수기호 제거, 정규 표현식\n",
    "        documents[i] = document\n",
    "\n",
    "    #텍스트 정제 (형태소 분석)\n",
    "    for i, document in enumerate(documents):\n",
    "        okt = konlpy.tag.Okt()\n",
    "        clean_words = []\n",
    "        for word in okt.pos(document, stem=True): #어간 추출\n",
    "            if word[1] in ['Noun', 'Verb', 'Adjective']: #명사, 동사, 형용사\n",
    "                clean_words.append(word[0])\n",
    "        document = ' '.join(clean_words)\n",
    "        documents[i] = document\n",
    "\n",
    "    #텍스트 정제 (불용어 제거)\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/cranberryai/todak_todak_python/master/machine_learning_text/clean_korean_documents/korean_stopwords.txt', header=None)\n",
    "    df[0] = df[0].apply(lambda x: x.strip())\n",
    "    stopwords = df[0].to_numpy()\n",
    "    nltk.download('punkt')\n",
    "    for i, document in enumerate(documents):\n",
    "        clean_words = []\n",
    "        for word in nltk.tokenize.word_tokenize(document):\n",
    "            if word not in stopwords: #불용어 제거\n",
    "                clean_words.append(word)\n",
    "        documents[i] = ' '.join(clean_words)\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "def clean_target_feature(data):\n",
    "    x_data = data.to_list()\n",
    "    return clean_korean_documents(x_data)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# 1.클린징할 파일 가져오기\n",
    "file = f'{PATH}/naver_{node}_{keyword}.csv'  # 앞에서 만들어진 파일 사용하기\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# 2.클린징할 컬럼 선택해서 클린징하기\n",
    "# (앞 OpenAPI검색에서 2.news 검색을 한 후 실행하기)\n",
    "df['제목'] = clean_target_feature(df['제목'])  # 기사 제목\n",
    "df['내용'] = clean_target_feature(df['내용'])  # 기사 내용\n",
    "\n",
    "# 3.클린징 결과 csv 파일로 저장하기\n",
    "file = f'{PATH}/naver_{node}_{keyword}_clean.csv'\n",
    "df.to_csv(file, index=False, encoding=\"utf-8-sig\")\n",
    "print(f'{file} SAVED')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4k38KlXmtWPn",
   "metadata": {
    "id": "4k38KlXmtWPn"
   },
   "source": [
    "#### 3.워드 클라우드 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vkCWhYlgt8c2",
   "metadata": {
    "id": "vkCWhYlgt8c2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "\n",
    "# 말뭉치를 토큰화하여 빈도수 가져오기\n",
    "def get_wordTokenCount(corpus):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "    # 말뭉치를 토큰화하기\n",
    "    vect = CountVectorizer().fit(corpus)\n",
    "    count = vect.transform(corpus).toarray().sum(axis=0)\n",
    "\n",
    "    # 토큰 빈도수로 정렬하고 토큰명 추출\n",
    "    idx = np.argsort(-count)  # 내림 정렬하여 인덱스 반환: 토큰의 인덱스\n",
    "    count = count[idx]        # 토큰의 빈도수\n",
    "    feature_name = np.array(vect.get_feature_names_out())[idx]  # 토큰값\n",
    "\n",
    "    # 빈도수 많은 순서대로 토큰명 10개만 출력\n",
    "    print(list(zip(feature_name, count))[:10])\n",
    "\n",
    "    return feature_name, count\n",
    "\n",
    "\n",
    "# 단어(토큰) 빈도수 막대 그래프 그리기\n",
    "def draw_wordTokenCountGraph(data, freq):\n",
    "    plt.bar(data, freq)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # 그래프 그림 저장히기\n",
    "    plt.savefig(f'./token_bar_graph.png')\n",
    "\n",
    "# 워드클라우드 만들기\n",
    "def make_wordcloud(feature_name, count):\n",
    "    # 한글 폰트 경로를 설정\n",
    "    # font_path = 'NanumGothic'  #/usr/share/fonts/truetype/nanum/NanumGothic.ttf  #코랩\n",
    "    font_path = 'malgun'  # C:/Windows/Fonts/                                  #window\n",
    "\n",
    "    # (토큰명, 빈도수) 딕셔너리 타입으로 변환\n",
    "    data = dict(zip(feature_name, count))\n",
    "\n",
    "    # 워드클라우드로 그래프로 시각화\n",
    "    wc = WordCloud(width = 1000, height = 600, background_color=\"black\", font_path=font_path)\n",
    "    plt.imshow(wc.generate_from_frequencies(data)) #딕셔너리\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # 이미지 파일로 저장하기\n",
    "    wc.to_file(f'./워드클라우드.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ijyL_9YSgg0q",
   "metadata": {
    "id": "ijyL_9YSgg0q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1.텍스트 말뭉치(corpus) 데이터 지정하기\n",
    "corpus = df['제목'].to_list()\n",
    "# print(corpus)\n",
    "\n",
    "# 2.말뭉치를 토큰화하여 빈도수 가져오기\n",
    "feature_name, count = get_wordTokenCount(corpus)\n",
    "\n",
    "# 3.단어(토큰) 빈도수 막대 그래프 그리기(상위 10개)\n",
    "# draw_wordTokenCountGraph(feature_name[:10], count[:10])\n",
    "\n",
    "# 3.워드 클라우드 만들기\n",
    "make_wordcloud(feature_name, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ajcnidsqs2hR",
   "metadata": {
    "id": "Ajcnidsqs2hR"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa45de",
   "metadata": {
    "id": "59fa45de"
   },
   "source": [
    "### <a name=\"3)웹이미지수집하기\">3) 웹 이미지 수집하기</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d3fd31",
   "metadata": {
    "id": "44d3fd31"
   },
   "source": [
    "#### 1.웹 이미지 화면에 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a091d",
   "metadata": {
    "id": "337a091d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://shopping-phinf.pstatic.net/main_3815224/38152244716.20230516165404.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680e362",
   "metadata": {
    "id": "0680e362"
   },
   "source": [
    "#### 2.웹 이미지 파일로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580299b",
   "metadata": {
    "id": "a580299b"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# 다운받을 이미지 url\n",
    "urls = [\n",
    "    \"https://shopping-phinf.pstatic.net/main_3815224/38152244716.20230516165404.jpg\",\n",
    "    \"https://shopping-phinf.pstatic.net/main_3726611/37266116619.20230119071117.jpg\"\n",
    "]\n",
    "# 파일로 저장하기\n",
    "for idx, url in enumerate(urls):\n",
    "    res = requests.get(url)                   # url 요청\n",
    "    img = Image.open(BytesIO(res.content))    # 응답결과(res.content)바이트파일 이미지 파일로 오픈\n",
    "    img.save(f'./testimg_{idx}.png', 'png')   # 'png'이미지로(만) 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf3dbf",
   "metadata": {
    "id": "cfdf3dbf"
   },
   "source": [
    "#### [실습] : 웹 이미지 수집하기\n",
    "- 앞에서 저장한 쇼핑 목록에 있는 URL을 이용하여 이미지 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc4ce14",
   "metadata": {
    "id": "9cc4ce14"
   },
   "outputs": [],
   "source": [
    "# 이미지 다운로드 하기\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 자신에게 맞게 폴더/파일 위치 정보를 수정한다.\n",
    "FILE = f'./data/naver_shop_샌들.csv'  # 앞에서 자신이 검색한 쇼핑 파일\n",
    "ImgFolder = f'./image/download/'      # 다운받을 이미지 폴더\n",
    "MAX = 10                              # 이미지 파일 다운로드 건수\n",
    "\n",
    "def getImageUrl(file):\n",
    "    print(f'읽은 파일명: {file}')\n",
    "    df = pd.read_csv(file, encoding='utf-8') # 이미지가 있는 쇼핑 파일 불러오기\n",
    "    return df['이미지'].to_list()\n",
    "\n",
    "def createDirectory(directory): # 다운받을 이미지 폴더 만들기\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            print(f'{directory} 폴더가 생성되었습니다.')\n",
    "            os.makedirs(directory)\n",
    "        print(f'이미지 폴더 위치 : {directory}')\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "def downloadImageFile(urls, imgfolder):\n",
    "    start = time.time()             # 이미지 다운로드 속도 time check\n",
    "    for idx, url in enumerate(urls):\n",
    "        if idx == MAX:\n",
    "            break  # MAX 건수만 처리하기\n",
    "        res = requests.get(url)     # request.get 요청\n",
    "#         print(f'[{idx+1:2>}][{time.time() - start}] : {url}')  # 이미지 다운로드 시간 체크\n",
    "        print(f'[{idx+1:0>2}] : {url}')  # 이미지 다운로드 시간 체크\n",
    "        img = Image.open(BytesIO(res.content))  #Img open\n",
    "        img.save(f'{imgfolder}testimage_{idx}.png', 'png')\n",
    "    return idx\n",
    "\n",
    "\n",
    "urls = getImageUrl(FILE)                # 이미지 URL 목록 가져오기\n",
    "createDirectory(ImgFolder)              # 다운받을 이미지 폴더 만들기\n",
    "totalcnt = downloadImageFile(urls, ImgFolder)      # 이미지 다운로드하기\n",
    "print(f'총 다운로드 건수: {totalcnt}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18b237",
   "metadata": {
    "id": "fb18b237"
   },
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd06d7e8",
   "metadata": {
    "id": "dd06d7e8"
   },
   "source": [
    "끝!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
